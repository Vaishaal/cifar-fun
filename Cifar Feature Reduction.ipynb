{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5167988e-f347-496e-abe3-310656310669"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['arccos', 'NAN']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import cifar_gpu_fun\n",
    "reload(cifar_gpu_fun)\n",
    "from cifar_gpu_fun import *\n",
    "from numba import jit\n",
    "import bcd\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import pyclust\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c640590a-a864-4de1-bdac-8f04d9c8def4"
    }
   },
   "source": [
    "#### Define Some Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5ee9705d-3093-4d0f-bd82-0e3dfcd14555"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FEATURE_BATCHES=1\n",
    "DATA_BATCH_SIZE=(1280)\n",
    "FEATURE_BATCH_SIZE=(1024)\n",
    "NUM_TRAIN = 50000\n",
    "NUM_TEST = 10000\n",
    "NUM_CLASSES = 10\n",
    "NUM_FEATURES = FEATURE_BATCH_SIZE * NUM_FEATURE_BATCHES * 8\n",
    "POOL_TYPE ='avg'\n",
    "FILTER_GEN ='empirical'\n",
    "BANDWIDTH = 1.0\n",
    "LAMBDAS = [0.01, 0.1, 1.0, 0.001]\n",
    "#LAMBDAS = [0.01]\n",
    "CUDA_CONVNET = True\n",
    "SCALE = 55.0\n",
    "BIAS = 1.25\n",
    "MIN_VAR_TOL = 1e-4\n",
    "TOT_FEAT = FEATURE_BATCH_SIZE*NUM_FEATURE_BATCHES\n",
    "NAN = float('nan')\n",
    "saved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)                                                                                                                                                                   \n",
    "(XTrain, labelsTrain), (XTest, labelsTest) = load_cifar_processed()\n",
    "patches = patchify_all_imgs(XTrain, (6,6), pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d4e10ddf-1e84-46e6-827c-649e44ec1642"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def rbf(K, gamma):\n",
    "    for x in range(K.shape[0]):\n",
    "        for y in range(K.shape[1]):\n",
    "            K[x,y] = math.exp(gamma*K[x,y])\n",
    "            \n",
    "    return K\n",
    "\n",
    "@jit(nopython=True)\n",
    "def arccos(K, XTrainNorms, XTestNorms):\n",
    "    for x in range(K.shape[0]):\n",
    "        for y in range(K.shape[1]):\n",
    "            testNorm = np.sqrt(XTestNorms[x])\n",
    "            trainNorm = np.sqrt(XTrainNorms[y]) \n",
    "            if (trainNorm == 0):\n",
    "                trainNorm = 1\n",
    "            if (testNorm == 0):\n",
    "                testNorm = 1 \n",
    "            cos = min(K[x,y]/(testNorm*trainNorm), 1)\n",
    "            theta = np.arccos(cos)\n",
    "            J = math.sin(theta) - (math.pi - theta)*math.cos(theta)\n",
    "            K[x,y] = 1.0/math.pi * J\n",
    "    return K\n",
    "    \n",
    "\n",
    "\n",
    "def computeRBFGramMatrix(K, XTrainNorms, XTestNorms, gamma=1, gamma_sample=10000):\n",
    "    \n",
    "    XTrainNorms = XTrainNorms.reshape(XTrainNorms.shape[0], 1)\n",
    "    XTestNorms = XTestNorms.reshape(XTestNorms.shape[0], 1)\n",
    "    print \"TURNING K -> DISTANCE\"\n",
    "    K *= -2\n",
    "    K += XTrainNorms.T\n",
    "    K += XTestNorms \n",
    "    if (gamma == None):\n",
    "        print \"Calculating gamma\"\n",
    "        samples = numpy.random.choice(K.shape[0], gamma_sample*2, replace=False)\n",
    "        x1 = samples[:gamma_sample]\n",
    "        x2 = samples[gamma_sample:]\n",
    "        sample_d = K[x1, x2]\n",
    "        print \"Sample d shape \", sample_d.shape\n",
    "        median = numpy.median(sample_d)\n",
    "        gamma = 2.0/median\n",
    "        print gamma\n",
    "    gamma = -1.0 * gamma\n",
    "\n",
    "    print \"Computing RBF\"\n",
    "    return rbf(K, gamma), -1.0*gamma\n",
    "\n",
    "def saveGramMatrix(KTrain, KTest, save_id=saved):\n",
    "    global saved\n",
    "    KFile = open(\"/data/vaishaal/cifar_kernels/cifar_kernel_{0}\".format(save_id), \"w+\")\n",
    "    np.savez(KFile, train=KTrain, test=KTest)\n",
    "    KFile.close()\n",
    "    saved += 1\n",
    "    \n",
    "def computeDistanceMatrix(XTest, XTrain):\n",
    "    XTrain = XTrain.reshape(XTrain.shape[0], -1)\n",
    "    XTest = XTest.reshape(XTest.shape[0], -1)\n",
    "    XTrain_norms = (np.linalg.norm(XTrain, axis=1) ** 2)[:, np.newaxis]\n",
    "    XTest_norms = (np.linalg.norm(XTest, axis=1) ** 2)[:, np.newaxis]\n",
    "    K = XTest.dot(XTrain.T)\n",
    "    K *= -2\n",
    "    K += XTrain_norms.T\n",
    "    K += XTest_norms  \n",
    "    return K\n",
    "    \n",
    "notebook_stdout = sys.stdout\n",
    "notebook_stderr = sys.stderr\n",
    "terminal_stdout = open('/dev/stdout', 'w')\n",
    "terminal_stderr = open('/dev/stderr', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_empirical_filter_gen_clustering(patches, labels, sampling=8, MIN_VAR_TOL=0, k=128, seed=0, num_base_filters=16384*2):\n",
    "    np.random.seed(seed)\n",
    "    patches = patches.reshape(patches.shape[0]*patches.shape[1],*patches.shape[2:])\n",
    "    all_idxs = np.random.choice(patches.shape[0], patches.shape[0], replace=False)\n",
    "    curr_idx = [0]\n",
    "    clustered_indices = [] \n",
    "    curr_clustered_idx = [0]\n",
    "    def empirical_filter_gen(num_filters):\n",
    "        clustered_left = (len(clustered_indices) - curr_clustered_idx[0])\n",
    "        while (clustered_left - num_filters <= 0):\n",
    "            uncluster_idxs = all_idxs[curr_idx[0]:curr_idx[0]+(num_filters*sampling)]\n",
    "            curr_idx[0] += num_filters*sampling\n",
    "            unclustered = patches[uncluster_idxs].astype('float32')\n",
    "            clustered_indices.extend(kmeans_cluster(unclustered, uncluster_idxs, k=k))\n",
    "            clustered_left = (len(clustered_indices) - curr_clustered_idx[0])\n",
    "            print(clustered_left)\n",
    "\n",
    "            \n",
    "        idxs = clustered_indices[curr_clustered_idx[0]:curr_clustered_idx[0]+num_filters]\n",
    "        curr_clustered_idx[0] += num_filters\n",
    "        unfiltered = patches[idxs].astype('float32').transpose(0,3,1,2)\n",
    "        old_shape = unfiltered.shape\n",
    "        unfiltered = unfiltered.reshape(unfiltered.shape[0], -1)\n",
    "        print(unfiltered.shape)\n",
    "        unfiltered_vars = np.var(unfiltered, axis=1)\n",
    "        filtered = unfiltered[np.where(unfiltered_vars > MIN_VAR_TOL)]\n",
    "        out = np.ascontiguousarray(filtered[:num_filters].reshape(num_filters, *old_shape[1:]).copy())\n",
    "        return out\n",
    "    return empirical_filter_gen\n",
    "\n",
    "def kmediods_cluster(data, indices, k=1024, seed=0):\n",
    "    print \"K={0}\".format(k)\n",
    "    print data.shape[0]\n",
    "    shp = data.shape\n",
    "    data = data.reshape(shp[0], -1)\n",
    "    data = np.ascontiguousarray(data)\n",
    "    ddt = data.dot(data.T)\n",
    "    pos = np.maximum(ddt - 1.0, 0)\n",
    "    neg = np.maximum(-1.0 * ddt - 1.0, 0)\n",
    "    featurized_patches = np.hstack((pos, neg))\n",
    "    print(\"RUNNING KMEDIODS\")\n",
    "    kmd = pyclust.KMedoids(n_clusters=k, n_trials=50)\n",
    "    kmd.fit(featurized_patches)\n",
    "    centers = kmd.centers_\n",
    "    clustered_indices = []\n",
    "    print centers.shape\n",
    "    print featurized_patches.shape\n",
    "    print(\"FINDING INDICES\")\n",
    "    for c in range(k):\n",
    "        for d in range(data.shape[0]):\n",
    "            if np.all(np.isclose(featurized_patches[d, :], centers[c, :])):\n",
    "                clustered_indices.append(d)\n",
    "                continue\n",
    "    return np.array(clustered_indices)\n",
    "\n",
    "\n",
    "def kmeans_cluster(data, indices, k=1024, seed=0):\n",
    "    print \"K={0}\".format(k)\n",
    "    print data.shape[0]\n",
    "    shp = data.shape\n",
    "    data = data.reshape(shp[0], -1)\n",
    "    data = np.ascontiguousarray(data)\n",
    "    ddt = data.dot(data.T)\n",
    "    pos = np.maximum(ddt - 1.0, 0)\n",
    "    neg = np.maximum(-1.0 * ddt - 1.0, 0)\n",
    "    featurized_patches = np.hstack((pos, neg))\n",
    "    print(\"RUNNING KMEANS\")\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(featurized_patches)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    clustered_indices = []\n",
    "    print centers.shape\n",
    "    print featurized_patches.shape\n",
    "    print(\"FINDING INDICES\")\n",
    "    d = metrics.pairwise.pairwise_distances(centers, featurized_patches)\n",
    "    clustered_indices = []\n",
    "    for c in range(k):\n",
    "        clustered_indices.append(np.argmin(d[c, :])) \n",
    "    return np.array(clustered_indices)\n",
    "        \n",
    "    \n",
    "    \n",
    "def greedy_cluster(filters, data, indices, k=10):\n",
    "    shp = data.shape\n",
    "    data = data.reshape(shp[0], -1)\n",
    "    data = np.ascontiguousarray(data)\n",
    "    ddt = data.dot(data.T)\n",
    "    pos = np.maximum(ddt - 1.0, 0)\n",
    "    neg = np.maximum(-1.0 * ddt - 1.0, 0)\n",
    "    featurized_patches = np.hstack((pos, neg))\n",
    "    distance_matrix = computeDistanceMatrix(featurized_patches, featurized_patches)\n",
    "    distance_matrix[np.diag_indices(distance_matrix.shape[0])] = float('inf')\n",
    "    \n",
    "    skip = set()\n",
    "    not_skip = []\n",
    "    print(\"computed distance matrix\")\n",
    "    for row in range(distance_matrix.shape[0]):\n",
    "        if row in skip:\n",
    "            continue\n",
    "        not_skip.append(row)\n",
    "        sorted_indices = np.argsort(distance_matrix[row, :]) \n",
    "        top_k = sorted_indices[:k]\n",
    "        distance_matrix[:, top_k] = float('inf')\n",
    "        for r in top_k:\n",
    "            skip.add(r)\n",
    "            \n",
    "    clustered_indices = indices[np.array(not_skip)]\n",
    "    return clustered_indices\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches_flattened = patches.reshape(patches.shape[0]*patches.shape[1], *patches.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "idxs = np.random.choice(patches_flattened.shape[0], 1024, replace=False)\n",
    "sampled = patches_flattened[idxs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=128\n",
      "1024\n",
      "RUNNING KMEANS\n",
      "(128, 2048)\n",
      "(1024, 2048)\n",
      "FINDING INDICES\n"
     ]
    }
   ],
   "source": [
    "clustered_idxs = kmeans_cluster(sampled, idxs, k=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  75,  739,   27,  286,   76,   95,  421,  277,  948,   67,  482,\n",
       "        393,  872,  411,  928,  235,  455,  650,  850,  154,  566,  291,\n",
       "        604,  898,  249,  113,  586,   19,   63,  195,  874,  790,  970,\n",
       "        193,  963,  798,  275,   62,  575,  977,  904,  423,  125,   71,\n",
       "        106,  513,  565, 1023,  992,  593,  437,  709,  848,    0,  676,\n",
       "        134,  618,  192,  364,  774,  720,  680,  981,  177,  555,  521,\n",
       "        768,  882,  828,  209,  415,  215,   33,  693,  986,  870,  909,\n",
       "       1017,  973,  347,  294,  562,  122,  974,  381,  233,   17,  991,\n",
       "        714,  897,  979,    8,  605,  227,  114,  626, 1001,  965,  976,\n",
       "        408,  149,   37,  630,  180,  728,  922,  343,  617,  317,  414,\n",
       "        572,  959, 1004,  544,  316,  846,  497,  988,  547,   30,  501,\n",
       "        663,  730,  267,  530,  108,  244,  888])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_gen = make_empirical_filter_gen_clustering(patches, labelsTrain,  sampling=4, MIN_VAR_TOL=0, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALID_3_POOLS = [(15,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-2436e58eb11d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLAMBDAS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainAndEvaluateDualModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"RESULT \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpool_stride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/vaishaal/cifar_fun/cifar_gpu_fun/cifar_gpu_fun.pyc\u001b[0m in \u001b[0;36mtrainAndEvaluateDualModel\u001b[1;34m(KTrain, KTest, labelsTrain, labelsTest, reg, TOT_FEAT, W)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrainAndEvaluateDualModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTOT_FEAT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearnDual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTOT_FEAT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTOT_FEAT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[0mpredTrainLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluateDualModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTOT_FEAT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTOT_FEAT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[0mpredTestLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluateDualModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTOT_FEAT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTOT_FEAT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/vaishaal/cifar_fun/cifar_gpu_fun/cifar_gpu_fun.pyc\u001b[0m in \u001b[0;36mlearnDual\u001b[1;34m(gramMatrix, labels, reg, W, TOT_FEAT, NUM_TRAIN)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[0mdiag_indices\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgramMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0mgramMatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdiag_indices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_inv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgramMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msym_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[0mgramMatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdiag_indices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_inv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/vaishaal/anaconda2/lib/python2.7/site-packages/scipy/linalg/basic.pyc\u001b[0m in \u001b[0;36msolve\u001b[1;34m(a, b, sym_pos, lower, overwrite_a, overwrite_b, debug, check_finite)\u001b[0m\n\u001b[0;32m     92\u001b[0m         c, x, info = posv(a1, b1, lower=lower,\n\u001b[0;32m     93\u001b[0m                           \u001b[0moverwrite_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverwrite_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                           overwrite_b=overwrite_b)\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mgesv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gesv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sys.stdout = terminal_stdout\n",
    "sys.stderr = terminal_stderr\n",
    "#sys.stdout = notebook_stdout\n",
    "#sys.stderr = notebook_stderr\n",
    "accs = []\n",
    "results = {}\n",
    "for param in VALID_3_POOLS:\n",
    "    pool_size, pool_stride = param\n",
    "    filter_gen = make_empirical_filter_gen_clustering(patches, labelsTrain, sampling=1, k=128, MIN_VAR_TOL=0, seed=3)\n",
    "    KTrain, KTest, normsTrain, normsTest, filters = convolveAndAccumulateGramAsync(XTrain, XTest, \n",
    "                                                                     labelsTrain, labelsTest, filter_gen,\n",
    "                                                                     num_feature_batches=NUM_FEATURE_BATCHES, pool_size=pool_size, pool_stride=pool_stride, sync=40)\n",
    "    \n",
    "    result = {}\n",
    "    for reg in LAMBDAS:\n",
    "        acc = trainAndEvaluateDualModel(KTrain, KTest, labelsTrain, labelsTest, reg=reg)\n",
    "        print \"RESULT \", pool_size,pool_stride, reg, acc\n",
    "        result[reg] = acc\n",
    "    results[param] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.stdout = terminal_stdout\n",
    "sys.stderr = terminal_stderr\n",
    "#sys.stdout = notebook_stdout\n",
    "#sys.stderr = notebook_stderr\n",
    "accs = []\n",
    "results_control = {}\n",
    "for param in VALID_3_POOLS:\n",
    "    pool_size, pool_stride = param\n",
    "    filter_gen = make_empirical_filter_gen(patches, labelsTrain, MIN_VAR_TOL=0, seed=3)\n",
    "    KTrain, KTest, normsTrain, normsTest, filters = convolveAndAccumulateGramAsync(XTrain, XTest, \n",
    "                                                                     labelsTrain, labelsTest, filter_gen,\n",
    "                                                                     num_feature_batches=NUM_FEATURE_BATCHES, pool_size=pool_size, pool_stride=pool_stride, sync=40)\n",
    "    \n",
    "    result = {}\n",
    "    for reg in LAMBDAS:\n",
    "        acc = trainAndEvaluateDualModel(KTrain, KTest, labelsTrain, labelsTest, reg=reg)\n",
    "        print \"RESULT \", pool_size,pool_stride, reg, acc\n",
    "        result[reg] = acc\n",
    "        result['cluster'] = False\n",
    "    results_control[param] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = notebook_stdout\n",
    "sys.stderr = notebook_stderr\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(15, 6): {'cluster': False, 0.001: (1.0, 0.78339999999999999), 0.1: (0.95955999999999997, 0.81930000000000003), 0.01: (0.99950000000000006, 0.82479999999999998), 1.0: (0.83904000000000001, 0.76970000000000005)}}\n"
     ]
    }
   ],
   "source": [
    "print results_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gammas = [0.005]\n",
    "regs = [0]\n",
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAMMA\n",
      "TURNING K -> DISTANCE\n",
      "Computing RBF\n",
      "TURNING K -> DISTANCE\n",
      "Computing RBF\n",
      "('Starting Train', 'reg', 0, 'gamma', 0.005)\n",
      "Learning Dual Model better\n",
      "REG IS  0\n",
      "CPU times: user 43min 51s, sys: 33 s, total: 44min 24s\n",
      "Wall time: 2min 16s\n",
      "1.0 0.8169 1 0 0.005\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = notebook_stdout\n",
    "sys.stderr = notebook_stderr\n",
    "for gamma in gammas:\n",
    "    print \"GAMMA\"\n",
    "    KTrainRBF = KTrain.copy()\n",
    "    KTestRBF = KTest.copy()\n",
    "    KTrainRBF, train_gamma = computeRBFGramMatrix(KTrainRBF, normsTrain, normsTrain, gamma=gamma)\n",
    "    KTestRBF, _ = computeRBFGramMatrix(KTestRBF, normsTrain, normsTest, gamma=train_gamma)\n",
    "    for reg in regs:\n",
    "        try:\n",
    "            print(\"Starting Train\",\"reg\", reg, \"gamma\", gamma)\n",
    "            sys.stdout.flush()\n",
    "            %time train,test = trainAndEvaluateDualModel(KTrainRBF, KTestRBF, labelsTrain, labelsTest, reg=reg)\n",
    "            print train,test,1,reg,gamma\n",
    "            sys.stdout.flush()\n",
    "            accs.append((gamma,reg,train,test))\n",
    "        except:\n",
    "            print(\"Singular Matrix\")\n",
    "            accs.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.stdout = notebook_stdout\n",
    "sys.stderr = notebook_stderr\n",
    "for i, acc in enumerate(accs):\n",
    "    gamma,reg,train, test = acc\n",
    "    print train,test,1,reg,gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KTrain_128 = np.load(\"/data/vaishaal/KTrain_128.npy\")\n",
    "KTest_128 = np.load(\"/data/vaishaal/KTest_128.npy\")\n",
    "normsTrain_128 = np.load(\"/data/vaishaal/norms_train_128.npy\")\n",
    "normsTest_128 = np.load(\"/data/vaishaal/norms_test_128.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KTrain_fuse = KTrain_128 + KTrain\n",
    "KTest_fuse = KTest_128 + KTest\n",
    "normsTrain_fuse = normsTrain_128 + normsTrain\n",
    "normsTest_fuse = normsTest_128 + normsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Dual Model better\n",
      "REG IS  0.01\n"
     ]
    }
   ],
   "source": [
    "acc1 = trainAndEvaluateDualModel(KTrain, KTest, labelsTrain, labelsTest, reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99973999999999996, 0.83530000000000004)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Dual Model better\n",
      "REG IS  0.05\n",
      "(0.99883999999999995, 0.82879999999999998)\n"
     ]
    }
   ],
   "source": [
    "acc2 = trainAndEvaluateDualModel(KTrain_fuse, KTest_fuse, labelsTrain, labelsTest, reg=0.05)\n",
    "print acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.83109999999999995)\n"
     ]
    }
   ],
   "source": [
    "print acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/data/vaishaal/KTrain_1024_patches\", KTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/data/vaishaal/KTest_1024_patches\", KTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/data/vaishaal/norms_train_1024_patches\", normsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/data/vaishaal/norms_test_1024_patches\", normsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/data/vaishaal/labels_train\", labelsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/data/vaishaal/labels_test\", labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del KTrain_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del KTrain_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 729, 6, 6, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURNING K -> DISTANCE\n"
     ]
    }
   ],
   "source": [
    "KTrainRBF = KTrain.copy()\n",
    "KTestRBF = KTest.copy()\n",
    "def kernel_to_distance(K, XTrainNorms, XTestNorms):\n",
    "    XTrainNorms = XTrainNorms.reshape(XTrainNorms.shape[0], 1)\n",
    "    XTestNorms = XTestNorms.reshape(XTestNorms.shape[0], 1)\n",
    "    print \"TURNING K -> DISTANCE\"\n",
    "    K *= -2\n",
    "    K += XTrainNorms.T\n",
    "    K += XTestNorms \n",
    "    return K\n",
    "\n",
    "def estimate_gamma(D,gamma_sample=10000):\n",
    "    print \"Calculating gamma\"\n",
    "    samples = numpy.random.choice(D.shape[0], gamma_sample*2, replace=False)\n",
    "    x1 = samples[:gamma_sample]\n",
    "    x2 = samples[gamma_sample:]\n",
    "    sample_d = D[x1, x2]\n",
    "    print \"Sample d shape \", sample_d.shape\n",
    "    median = np.median(sample_d)\n",
    "    gamma = 2.0/median\n",
    "    return gamma\n",
    "D = kernel_to_distance(KTrainRBF, normsTrain, normsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample d shape  (1000,)\n"
     ]
    }
   ],
   "source": [
    "pts = np.random.choice(D.shape[0], 1000*2, replace=False)\n",
    "x1 = pts[:1000]\n",
    "x2 = pts[1000:]\n",
    "sample_d = D[x1, x2]\n",
    "print \"Sample d shape \", sample_d.shape\n",
    "median = np.median(sample_d)\n",
    "gamma = 2.0/median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KTrain = KTrainRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   7.62939453e-06,   0.00000000e+00, ...,\n",
       "         1.90734863e-06,   0.00000000e+00,   0.00000000e+00])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 33.20146561,  36.28236389,  15.55484772, ...,  17.90564346,\n",
       "         25.23268318,  29.74692154],\n",
       "       [ 36.28236389,  44.59234619,  17.80164909, ...,  20.59594727,\n",
       "         30.45558167,  34.82453918],\n",
       "       [ 15.55484772,  17.80164909,   9.16023064, ...,   9.84381771,\n",
       "         11.05340576,  15.00150013],\n",
       "       ..., \n",
       "       [ 17.90564346,  20.59594727,   9.84381771, ...,  11.95548248,\n",
       "         13.03578663,  17.35746956],\n",
       "       [ 25.23268318,  30.45558167,  11.05340576, ...,  13.03578663,\n",
       "         25.01102257,  24.62996674],\n",
       "       [ 29.74692154,  34.82453918,  15.00150013, ...,  17.35746956,\n",
       "         24.62996674,  31.18713188]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KTrainRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   5.22908783e+00,   1.12520008e+01, ...,\n",
       "          9.34566212e+00,   7.74712181e+00,   4.89475441e+00],\n",
       "       [  5.22908783e+00,   7.62939453e-06,   1.81492825e+01, ...,\n",
       "          1.53559389e+01,   8.69220924e+00,   6.13040352e+00],\n",
       "       [  1.12520008e+01,   1.81492825e+01,   0.00000000e+00, ...,\n",
       "          1.42807865e+00,   1.20644417e+01,   1.03443623e+01],\n",
       "       ..., \n",
       "       [  9.34566212e+00,   1.53559389e+01,   1.42807865e+00, ...,\n",
       "          1.90734863e-06,   1.08949327e+01,   8.42767620e+00],\n",
       "       [  7.74712181e+00,   8.69220924e+00,   1.20644417e+01, ...,\n",
       "          1.08949327e+01,   0.00000000e+00,   6.93822098e+00],\n",
       "       [  4.89475441e+00,   6.13040352e+00,   1.03443623e+01, ...,\n",
       "          8.42767620e+00,   6.93822098e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 33.20146561,  36.28236389,  15.55484772, ...,  17.90564346,\n",
       "         25.23268318,  29.74692154],\n",
       "       [ 36.28236389,  44.59234619,  17.80164909, ...,  20.59594727,\n",
       "         30.45558167,  34.82453918],\n",
       "       [ 15.55484772,  17.80164909,   9.16023064, ...,   9.84381771,\n",
       "         11.05340576,  15.00150013],\n",
       "       ..., \n",
       "       [ 17.90564346,  20.59594727,   9.84381771, ...,  11.95548248,\n",
       "         13.03578663,  17.35746956],\n",
       "       [ 25.23268318,  30.45558167,  11.05340576, ...,  13.03578663,\n",
       "         25.01102257,  24.62996674],\n",
       "       [ 29.74692154,  34.82453918,  15.00150013, ...,  17.35746956,\n",
       "         24.62996674,  31.18713188]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33.20146561,  44.59235001,   9.16023064, ...,  11.95548344,\n",
       "        25.01102257,  31.18713188], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normsTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "691889e3-b7c6-4914-802f-c045471bb148": {
     "id": "691889e3-b7c6-4914-802f-c045471bb148",
     "prev": null,
     "regions": {
      "d473ec79-b583-4b90-8f0c-ca04540a8b42": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "d473ec79-b583-4b90-8f0c-ca04540a8b42"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
